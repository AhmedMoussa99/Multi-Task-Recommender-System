{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82daeca7",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a281cb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import missingno\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from recommenders.models.deeprec.models.graphrec.lightgcn import LightGCN\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# from recommenders.models.deeprec.deeprec_utils import prepare_hparams\n",
    "import dgl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce593911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dgl\n",
      "  Using cached dgl-1.1.1-cp39-cp39-manylinux1_x86_64.whl (6.3 MB)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.9/site-packages (from dgl) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.9/site-packages (from dgl) (1.9.1)\n",
      "Requirement already satisfied: networkx>=2.1 in /opt/conda/lib/python3.9/site-packages (from dgl) (2.5.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.9/site-packages (from dgl) (2.29.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from dgl) (4.65.0)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /opt/conda/lib/python3.9/site-packages (from dgl) (5.9.5)\n",
      "Requirement already satisfied: decorator<5,>=4.3 in /opt/conda/lib/python3.9/site-packages (from networkx>=2.1->dgl) (4.4.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->dgl) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->dgl) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->dgl) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->dgl) (2022.12.7)\n",
      "Installing collected packages: dgl\n",
      "Successfully installed dgl-1.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install dgl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3a9c28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting missingno\n",
      "  Using cached missingno-0.5.2-py3-none-any.whl (8.7 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from missingno) (1.23.5)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.9/site-packages (from missingno) (3.7.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.9/site-packages (from missingno) (1.9.1)\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.9/site-packages (from missingno) (0.12.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib->missingno) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.9/site-packages (from matplotlib->missingno) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib->missingno) (4.39.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib->missingno) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib->missingno) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib->missingno) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib->missingno) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.9/site-packages (from matplotlib->missingno) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib->missingno) (5.12.0)\n",
      "Requirement already satisfied: pandas>=0.25 in /opt/conda/lib/python3.9/site-packages (from seaborn->missingno) (2.0.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/conda/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib->missingno) (3.15.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas>=0.25->seaborn->missingno) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.9/site-packages (from pandas>=0.25->seaborn->missingno) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib->missingno) (1.16.0)\n",
      "Installing collected packages: missingno\n",
      "Successfully installed missingno-0.5.2\n"
     ]
    }
   ],
   "source": [
    "!pip install missingno"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4910e2bd",
   "metadata": {},
   "source": [
    "## Read the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2c174f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataa = pd.read_csv('ctr_data_1M_modified.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745d2183",
   "metadata": {},
   "source": [
    "### Take a sample from the dataset. A million record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d4c9ef35",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataa.sample(n=1000000, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "31a9ff82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>click</th>\n",
       "      <th>follow</th>\n",
       "      <th>like</th>\n",
       "      <th>share</th>\n",
       "      <th>video_category</th>\n",
       "      <th>watching_times</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hist_1</th>\n",
       "      <th>hist_2</th>\n",
       "      <th>hist_3</th>\n",
       "      <th>hist_4</th>\n",
       "      <th>hist_5</th>\n",
       "      <th>hist_6</th>\n",
       "      <th>hist_7</th>\n",
       "      <th>hist_8</th>\n",
       "      <th>hist_9</th>\n",
       "      <th>hist_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21508185</th>\n",
       "      <td>153098</td>\n",
       "      <td>1369942</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1886</td>\n",
       "      <td>21660</td>\n",
       "      <td>290301</td>\n",
       "      <td>3944</td>\n",
       "      <td>71249</td>\n",
       "      <td>62141</td>\n",
       "      <td>62903</td>\n",
       "      <td>2117</td>\n",
       "      <td>36473</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68059050</th>\n",
       "      <td>511148</td>\n",
       "      <td>1534</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>15717</td>\n",
       "      <td>855</td>\n",
       "      <td>3138</td>\n",
       "      <td>152</td>\n",
       "      <td>46097</td>\n",
       "      <td>145574</td>\n",
       "      <td>2986</td>\n",
       "      <td>89964</td>\n",
       "      <td>2106</td>\n",
       "      <td>1425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74617845</th>\n",
       "      <td>566038</td>\n",
       "      <td>1380004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3537</td>\n",
       "      <td>14580</td>\n",
       "      <td>24059</td>\n",
       "      <td>1932</td>\n",
       "      <td>48184</td>\n",
       "      <td>1442</td>\n",
       "      <td>301</td>\n",
       "      <td>1356871</td>\n",
       "      <td>1353656</td>\n",
       "      <td>1381411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86042747</th>\n",
       "      <td>662993</td>\n",
       "      <td>20406</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>217</td>\n",
       "      <td>237931</td>\n",
       "      <td>7336</td>\n",
       "      <td>5302</td>\n",
       "      <td>1099</td>\n",
       "      <td>20807</td>\n",
       "      <td>64</td>\n",
       "      <td>23576</td>\n",
       "      <td>1305</td>\n",
       "      <td>84673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4049227</th>\n",
       "      <td>29918</td>\n",
       "      <td>47146</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>25230</td>\n",
       "      <td>1075</td>\n",
       "      <td>21289</td>\n",
       "      <td>62442</td>\n",
       "      <td>9440</td>\n",
       "      <td>59868</td>\n",
       "      <td>12935</td>\n",
       "      <td>31318</td>\n",
       "      <td>35093</td>\n",
       "      <td>10825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440518</th>\n",
       "      <td>18106</td>\n",
       "      <td>32023</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>38132</td>\n",
       "      <td>83331</td>\n",
       "      <td>15654</td>\n",
       "      <td>83332</td>\n",
       "      <td>41739</td>\n",
       "      <td>80588</td>\n",
       "      <td>9917</td>\n",
       "      <td>5015</td>\n",
       "      <td>11324</td>\n",
       "      <td>4081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112889086</th>\n",
       "      <td>930728</td>\n",
       "      <td>1429780</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1357685</td>\n",
       "      <td>1356855</td>\n",
       "      <td>1356738</td>\n",
       "      <td>1412813</td>\n",
       "      <td>1452179</td>\n",
       "      <td>1381563</td>\n",
       "      <td>1356802</td>\n",
       "      <td>1574881</td>\n",
       "      <td>1361787</td>\n",
       "      <td>1483510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109094921</th>\n",
       "      <td>889508</td>\n",
       "      <td>1358622</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1384358</td>\n",
       "      <td>1357301</td>\n",
       "      <td>1354712</td>\n",
       "      <td>1352836</td>\n",
       "      <td>1354063</td>\n",
       "      <td>1356635</td>\n",
       "      <td>27915</td>\n",
       "      <td>1377335</td>\n",
       "      <td>1358332</td>\n",
       "      <td>1369234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8179276</th>\n",
       "      <td>59938</td>\n",
       "      <td>1368961</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>976</td>\n",
       "      <td>921</td>\n",
       "      <td>49355</td>\n",
       "      <td>943</td>\n",
       "      <td>340</td>\n",
       "      <td>154411</td>\n",
       "      <td>1778</td>\n",
       "      <td>58902</td>\n",
       "      <td>5271</td>\n",
       "      <td>14976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12572496</th>\n",
       "      <td>91123</td>\n",
       "      <td>21125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>968</td>\n",
       "      <td>7845</td>\n",
       "      <td>57492</td>\n",
       "      <td>88992</td>\n",
       "      <td>10085</td>\n",
       "      <td>8004</td>\n",
       "      <td>160001</td>\n",
       "      <td>164463</td>\n",
       "      <td>10617</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           user_id  item_id  click  follow  like  share  video_category  \\\n",
       "21508185    153098  1369942      0       0     0      0               0   \n",
       "68059050    511148     1534      0       0     0      0               1   \n",
       "74617845    566038  1380004      0       0     0      0               0   \n",
       "86042747    662993    20406      0       0     0      0               0   \n",
       "4049227      29918    47146      1       0     0      0               0   \n",
       "...            ...      ...    ...     ...   ...    ...             ...   \n",
       "2440518      18106    32023      0       0     0      0               0   \n",
       "112889086   930728  1429780      1       0     0      0               1   \n",
       "109094921   889508  1358622      0       0     0      0               0   \n",
       "8179276      59938  1368961      0       0     0      0               1   \n",
       "12572496     91123    21125      0       0     0      0               0   \n",
       "\n",
       "           watching_times  gender  age   hist_1   hist_2   hist_3   hist_4  \\\n",
       "21508185                1       1    2     1886    21660   290301     3944   \n",
       "68059050                0       1    3    15717      855     3138      152   \n",
       "74617845                1       2    6     3537    14580    24059     1932   \n",
       "86042747                0       2    2      217   237931     7336     5302   \n",
       "4049227                 3       2    2    25230     1075    21289    62442   \n",
       "...                   ...     ...  ...      ...      ...      ...      ...   \n",
       "2440518                 1       2    2    38132    83331    15654    83332   \n",
       "112889086               1       1    4  1357685  1356855  1356738  1412813   \n",
       "109094921               0       1    4  1384358  1357301  1354712  1352836   \n",
       "8179276                 0       1    2      976      921    49355      943   \n",
       "12572496                1       0    0      968     7845    57492    88992   \n",
       "\n",
       "            hist_5   hist_6   hist_7   hist_8   hist_9  hist_10  \n",
       "21508185     71249    62141    62903     2117    36473      141  \n",
       "68059050     46097   145574     2986    89964     2106     1425  \n",
       "74617845     48184     1442      301  1356871  1353656  1381411  \n",
       "86042747      1099    20807       64    23576     1305    84673  \n",
       "4049227       9440    59868    12935    31318    35093    10825  \n",
       "...            ...      ...      ...      ...      ...      ...  \n",
       "2440518      41739    80588     9917     5015    11324     4081  \n",
       "112889086  1452179  1381563  1356802  1574881  1361787  1483510  \n",
       "109094921  1354063  1356635    27915  1377335  1358332  1369234  \n",
       "8179276        340   154411     1778    58902     5271    14976  \n",
       "12572496     10085     8004   160001   164463    10617       47  \n",
       "\n",
       "[1000000 rows x 20 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7e560ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ctr_data_1M dataset has 1000000 samples and 20 features.\n"
     ]
    }
   ],
   "source": [
    "print(f\"ctr_data_1M dataset has {data.shape[0]} samples and {data.shape[1]} features.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a84239",
   "metadata": {},
   "source": [
    "# Modeling ESMM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c855a400",
   "metadata": {},
   "source": [
    "ESMM Model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ee165b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Reference:\n",
    "    [1]Xiao Ma et al. Entire space multi-task model: An effective approach for estimating post-click conversion rate. In The 41st International\n",
    "    ACM SIGIR Conference on Research & Development in Information Retrieval, pages 1137–1140, 2018.\n",
    "Reference:\n",
    "    https://github.com/busesese/MultiTaskModel\n",
    "    https://github.com/yuangh-x/2022-NIPS-Tenrec/blob/master/model/mtl/esmm.py\n",
    "'''\n",
    "\n",
    "class ESMM(nn.Module):\n",
    "    def __init__(self, user_feature_dict, item_feature_dict, emb_dim=128, hidden_dim=[128, 64], dropouts=[0.5, 0.5],\n",
    "                 output_size=1, num_task=2):\n",
    "        \"\"\"\n",
    "        esmm model input parameters\n",
    "        :param user_feature_dict: user feature dict include: {feature_name: (feature_unique_num, feature_index)}\n",
    "        :param item_feature_dict: item feature dict include: {feature_name: (feature_unique_num, feature_index)}\n",
    "        :param emb_dim: int, embedding size\n",
    "        :param hidden_dim: list of ctr and ctcvr dnn hidden sizes\n",
    "        :param dropouts: list of ctr and ctcvr dnn drop out probability\n",
    "        :param output_size: int out put size\n",
    "        :param num_task: int default 2 multitask numbers\n",
    "        \"\"\"\n",
    "        super(ESMM, self).__init__()\n",
    "        \n",
    "        # check input parameters\n",
    "        if user_feature_dict is None or item_feature_dict is None:\n",
    "            raise Exception(\"input parameter user_feature_dict and item_feature_dict must be not None\")\n",
    "        if isinstance(user_feature_dict, dict) is False or isinstance(item_feature_dict, dict) is False:\n",
    "            raise Exception(\"input parameter user_feature_dict and item_feature_dict must be dict\")\n",
    "        \n",
    "        self.user_feature_dict = user_feature_dict\n",
    "        self.item_feature_dict = item_feature_dict\n",
    "        self.num_task = num_task\n",
    "        \n",
    "        # embedding初始化\n",
    "        user_cate_feature_nums, item_cate_feature_nums = 0, 0\n",
    "        for user_cate, num in self.user_feature_dict.items():\n",
    "            if num[0] > 1:\n",
    "                user_cate_feature_nums += 1\n",
    "                setattr(self, user_cate, nn.Embedding(num[0], emb_dim))\n",
    "        for item_cate, num in self.item_feature_dict.items():\n",
    "            if num[0] > 1:\n",
    "                item_cate_feature_nums += 1\n",
    "                setattr(self, item_cate, nn.Embedding(num[0], emb_dim))\n",
    "                \n",
    "        # user embedding + item embedding\n",
    "        hidden_size = emb_dim * (user_cate_feature_nums + item_cate_feature_nums) + \\\n",
    "                      (len(user_feature_dict) - user_cate_feature_nums) + (len(item_feature_dict) - item_cate_feature_nums)\n",
    "        \n",
    "        # esmm 独立任务的DNN结构\n",
    "        for i in range(self.num_task):\n",
    "            setattr(self, 'task_{}_dnn'.format(i + 1), nn.ModuleList())\n",
    "            hid_dim = [hidden_size] + hidden_dim\n",
    "            for j in range(len(hid_dim) - 1):\n",
    "                getattr(self, 'task_{}_dnn'.format(i + 1)).add_module('ctr_hidden_{}'.format(j),\n",
    "                                                                      nn.Linear(hid_dim[j], hid_dim[j + 1]))\n",
    "                getattr(self, 'task_{}_dnn'.format(i + 1)).add_module('ctr_batchnorm_{}'.format(j),\n",
    "                                                                      nn.BatchNorm1d(hid_dim[j + 1]))\n",
    "                getattr(self, 'task_{}_dnn'.format(i + 1)).add_module('ctr_dropout_{}'.format(j),\n",
    "                                                                      nn.Dropout(dropouts[j]))\n",
    "            getattr(self, 'task_{}_dnn'.format(i + 1)).add_module('task_last_layer',\n",
    "                                                                  nn.Linear(hid_dim[-1], output_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        assert x.size()[1] == len(self.item_feature_dict) + len(self.user_feature_dict)\n",
    "        # embedding\n",
    "        user_embed_list, item_embed_list = list(), list()\n",
    "        for user_feature, num in self.user_feature_dict.items():\n",
    "            if num[0] > 1:\n",
    "                user_embed_list.append(getattr(self, user_feature)(x[:, num[1]].long()))\n",
    "            else:\n",
    "                user_embed_list.append(x[:, num[1]].unsqueeze(1))\n",
    "        for item_feature, num in self.item_feature_dict.items():\n",
    "            if num[0] > 1:\n",
    "                item_embed_list.append(getattr(self, item_feature)(x[:, num[1]].long()))\n",
    "            else:\n",
    "                item_embed_list.append(x[:, num[1]].unsqueeze(1))\n",
    "            \n",
    "        # embedding 融合\n",
    "        user_embed = torch.cat(user_embed_list, axis=1)\n",
    "        item_embed = torch.cat(item_embed_list, axis=1)\n",
    "        \n",
    "        # hidden layer\n",
    "        hidden = torch.cat([user_embed, item_embed], axis=1).float()\n",
    "\n",
    "        # task tower\n",
    "        task_outputs = list()\n",
    "        for i in range(self.num_task):\n",
    "            x = hidden\n",
    "            for mod in getattr(self, 'task_{}_dnn'.format(i + 1)):\n",
    "                x = mod(x)\n",
    "            task_outputs.append(x)\n",
    "\n",
    "        return task_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "84d87396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>click</th>\n",
       "      <th>follow</th>\n",
       "      <th>like</th>\n",
       "      <th>share</th>\n",
       "      <th>video_category</th>\n",
       "      <th>watching_times</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hist_1</th>\n",
       "      <th>hist_2</th>\n",
       "      <th>hist_3</th>\n",
       "      <th>hist_4</th>\n",
       "      <th>hist_5</th>\n",
       "      <th>hist_6</th>\n",
       "      <th>hist_7</th>\n",
       "      <th>hist_8</th>\n",
       "      <th>hist_9</th>\n",
       "      <th>hist_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21508185</th>\n",
       "      <td>153098</td>\n",
       "      <td>1369942</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1886</td>\n",
       "      <td>21660</td>\n",
       "      <td>290301</td>\n",
       "      <td>3944</td>\n",
       "      <td>71249</td>\n",
       "      <td>62141</td>\n",
       "      <td>62903</td>\n",
       "      <td>2117</td>\n",
       "      <td>36473</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68059050</th>\n",
       "      <td>511148</td>\n",
       "      <td>1534</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>15717</td>\n",
       "      <td>855</td>\n",
       "      <td>3138</td>\n",
       "      <td>152</td>\n",
       "      <td>46097</td>\n",
       "      <td>145574</td>\n",
       "      <td>2986</td>\n",
       "      <td>89964</td>\n",
       "      <td>2106</td>\n",
       "      <td>1425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id  item_id  click  follow  like  share  video_category  \\\n",
       "21508185   153098  1369942      0       0     0      0               0   \n",
       "68059050   511148     1534      0       0     0      0               1   \n",
       "\n",
       "          watching_times  gender  age  hist_1  hist_2  hist_3  hist_4  hist_5  \\\n",
       "21508185               1       1    2    1886   21660  290301    3944   71249   \n",
       "68059050               0       1    3   15717     855    3138     152   46097   \n",
       "\n",
       "          hist_6  hist_7  hist_8  hist_9  hist_10  \n",
       "21508185   62141   62903    2117   36473      141  \n",
       "68059050  145574    2986   89964    2106     1425  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ce4e24e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000014\n",
      "2\n",
      "7\n",
      "3862454\n",
      "1\n",
      "124\n"
     ]
    }
   ],
   "source": [
    "print(data['user_id'].max())\n",
    "print(data['gender'].max())\n",
    "print(data['age'].max())\n",
    "print(data['item_id'].max())\n",
    "print(data['video_category'].max())\n",
    "print(data['watching_times'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a38971",
   "metadata": {},
   "source": [
    "### Preparing the data for training an ESMM (Entire Space Multi-Task Model) using PyTorch. \n",
    "\n",
    "It processes the dataset, converts target labels to binary values, specifies categorical columns, splits the data into training and testing sets, and creates custom PyTorch Dataset objects to hold the features and labels. The resulting datasets, along with dictionaries for user and item features, are returned for training the ESMM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "77ab5f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "def data_preparation():\n",
    "    \n",
    "    # First group of tasks according to the paper\n",
    "    label_columns = ['click', 'like']\n",
    "    \n",
    "    # Categorical columns in your dataset\n",
    "    categorical_columns = ['user_id', 'item_id', 'video_category', 'gender', 'age', 'watching_times']\n",
    "    \n",
    "    # Process the labels\n",
    "    for col in label_columns:\n",
    "        data[col] = data[col].apply(lambda x: 1 if x == 1 else 0)\n",
    "        \n",
    "    user_feature_dict = {'user_id': (1000054, 0), 'gender': (5, 4), 'age': (9, 5)}\n",
    "    item_feature_dict = {'item_id': (3862554, 1), 'video_category': (5, 2), 'watching_times': (170, 3)}\n",
    "    \n",
    "    # Split your data into train and test sets\n",
    "    train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Prepare train_dataset and test_dataset\n",
    "    train_dataset = TrainDataSet(train_data.iloc[:, :-2].values, (train_data['click'].values, train_data['like'].values))\n",
    "    test_dataset = TrainDataSet(test_data.iloc[:, :-2].values, (test_data['click'].values, test_data['like'].values))\n",
    "\n",
    "    return train_dataset, test_dataset, user_feature_dict, item_feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8917fe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TrainDataSet(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels_click = labels[0]\n",
    "        self.labels_like = labels[1]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        feature = self.features[index]\n",
    "        label_click = self.labels_click[index]\n",
    "        label_like = self.labels_like[index]\n",
    "        return feature, label_click, label_like\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731378b2",
   "metadata": {},
   "source": [
    "### Training function\n",
    "PyTorch training function for the ESMM (Entire Space Multi-Task Model). It trains the model using the specified number of epochs, given training and validation data loaders. The model is optimized using the provided loss function and optimizer. The training progress, including loss and AUC values, is displayed for each epoch. The function also implements early stopping based on the validation loss to prevent overfitting. The trained model is saved to the specified model_path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c7dbf440",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def train_model(esmm_model, train_dataloader, val_dataloader, num_epochs, loss_function, optimizer, model_path, early_stop):\n",
    "    \"\"\"\n",
    "    Train the ESMM model.\n",
    "    \n",
    "    Args:\n",
    "        esmm_model (ESMM): The ESMM model instance.\n",
    "        train_dataloader (DataLoader): DataLoader for the training data.\n",
    "        val_dataloader (DataLoader): DataLoader for the validation data.\n",
    "        num_epochs (int): Number of epochs to train the model.\n",
    "        loss_function: Loss function for training.\n",
    "        optimizer: Optimizer for model parameters.\n",
    "        model_path (str): Path to save the trained model.\n",
    "        early_stop (int): Number of epochs to wait for validation loss improvement before early stopping.\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    esmm_model.to(device)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    patience = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0.0\n",
    "        train_predictions_click = []\n",
    "        train_labels_click = []\n",
    "        train_predictions_like = []\n",
    "        train_labels_like = []\n",
    "\n",
    "        # Training\n",
    "        esmm_model.train()\n",
    "        for batch_input, batch_label_click, batch_label_like in tqdm(train_dataloader, desc=f\"Epoch {epoch+1}\"):\n",
    "            batch_input = batch_input.to(device)\n",
    "            batch_label_click = batch_label_click.to(device)\n",
    "            batch_label_like = batch_label_like.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = esmm_model(batch_input)\n",
    "            loss1 = loss_function(outputs[0], batch_label_click.unsqueeze(1).float())\n",
    "            loss2 = loss_function(outputs[1], batch_label_like.unsqueeze(1).float())\n",
    "            loss = loss1 + loss2\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * batch_input.size(0)\n",
    "\n",
    "            train_predictions_click.extend(outputs[0].squeeze().detach().cpu().numpy())\n",
    "            train_labels_click.extend(batch_label_click.squeeze().cpu().numpy())\n",
    "            train_predictions_like.extend(outputs[1].squeeze().detach().cpu().numpy())\n",
    "            train_labels_like.extend(batch_label_like.squeeze().cpu().numpy())\n",
    "        \n",
    "        train_loss /= len(train_dataloader.dataset)\n",
    "        train_auc = roc_auc_score(train_labels, train_predictions)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1} - Train Loss: {train_loss:.4f} - Train AUC: {train_auc:.4f}\")\n",
    "        \n",
    "        # Validation\n",
    "        val_loss = 0.0\n",
    "        val_predictions = []\n",
    "        val_labels = []\n",
    "        \n",
    "        esmm_model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_input, batch_label1, batch_label2 in tqdm(val_dataloader, desc=f\"Epoch {epoch+1} - Validation\"):\n",
    "                batch_input = batch_input.to(device)\n",
    "                batch_label1 = batch_label1.to(device)\n",
    "                batch_label2 = batch_label2.to(device)\n",
    "                \n",
    "                outputs = esmm_model(batch_input)\n",
    "                loss1 = loss_function(outputs[0], batch_label1.unsqueeze(1).float())\n",
    "                loss2 = loss_function(outputs[1], batch_label2.unsqueeze(1).float())\n",
    "                loss = loss1 + loss2\n",
    "                \n",
    "                val_loss += loss.item() * batch_input.size(0)\n",
    "                \n",
    "                val_predictions.extend(outputs[0].squeeze().detach().cpu().numpy())\n",
    "                val_labels.extend(batch_label1.squeeze().cpu().numpy())\n",
    "        \n",
    "        val_loss /= len(val_dataloader.dataset)\n",
    "        val_auc = roc_auc_score(val_labels, val_predictions)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1} - Validation Loss: {val_loss:.4f} - Validation AUC: {val_auc:.4f}\")\n",
    "        \n",
    "        # Check for early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience = 0\n",
    "            torch.save(esmm_model.state_dict(), model_path)\n",
    "        else:\n",
    "            patience += 1\n",
    "            if patience >= early_stop:\n",
    "                print(f\"No improvement in validation loss for {early_stop} epochs. Early stopping.\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4368c543",
   "metadata": {},
   "source": [
    "### Train and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3fc5392f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/25000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m early_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mesmm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_esmm.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[46], line 41\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(esmm_model, train_dataloader, val_dataloader, num_epochs, loss_function, optimizer, model_path, early_stop)\u001b[0m\n\u001b[1;32m     37\u001b[0m batch_label_like \u001b[38;5;241m=\u001b[39m batch_label_like\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     39\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 41\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mesmm_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m loss1 \u001b[38;5;241m=\u001b[39m loss_function(outputs[\u001b[38;5;241m0\u001b[39m], batch_label_click\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[1;32m     43\u001b[0m loss2 \u001b[38;5;241m=\u001b[39m loss_function(outputs[\u001b[38;5;241m1\u001b[39m], batch_label_like\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat())\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[41], line 65\u001b[0m, in \u001b[0;36mESMM.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m x\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_feature_dict) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_feature_dict)\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;66;03m# embedding\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     user_embed_list, item_embed_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(), \u001b[38;5;28mlist\u001b[39m()\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_dataset, test_dataset, user_feature_dict, item_feature_dict = data_preparation()\n",
    "\n",
    "# Define the batch size for training\n",
    "batch_size = 32\n",
    "\n",
    "# Create DataLoader objects for train and test datasets\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Define the ESMM model\n",
    "esmm = ESMM(user_feature_dict, item_feature_dict, emb_dim=64)\n",
    "\n",
    "# Define the loss function\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.Adam(esmm.parameters(), lr=0.01)\n",
    "\n",
    "# Define the number of training epochs\n",
    "num_epochs = 20\n",
    "# Define the early stopping parameter\n",
    "early_stop = 3\n",
    "\n",
    "# Train the model\n",
    "train_model(esmm, train_dataloader, test_dataloader, num_epochs, loss_fn, optimizer, 'model_esmm.pt', early_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8daeb7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_feature_dict = {'user_id': (1000054, 0), 'gender': (5, 4), 'age': (9, 5)}\n",
    "item_feature_dict = {'item_id': (3862554, 1), 'video_category': (5, 2), 'watching_times': (170, 3)}\n",
    "\n",
    "esmm_model = ESMM(user_feature_dict, item_feature_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c85045f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['user_id', 'item_id', 'video_category', 'watching_times', 'gender', 'age']\n",
    "\n",
    "x = torch.tensor(data[selected_columns].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f2459009",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = esmm_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bc88a95e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Outputs:\n",
      "Task 1: tensor([[-0.9761],\n",
      "        [-0.0262],\n",
      "        [-0.2407],\n",
      "        [ 0.3445],\n",
      "        [-0.4559]], grad_fn=<SliceBackward0>)\n",
      "Task 2: tensor([[ 0.1649],\n",
      "        [-0.1276],\n",
      "        [-0.3530],\n",
      "        [-1.6469],\n",
      "        [ 0.0116]], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Print the outputs\n",
    "print(\"Model Outputs:\")\n",
    "for i, output in enumerate(outputs[:5]):\n",
    "    print(\"Task {}: {}\".format(i+1, output[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f6a6efa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Click Predictions (Binary):\n",
      " [0 1 0 ... 0 0 1]\n",
      "Like Predictions (Binary):\n",
      " [0 0 1 ... 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'outputs' is the list of tensors containing the predictions\n",
    "click_predictions = outputs[0].detach().numpy().flatten()\n",
    "like_predictions = outputs[1].detach().numpy().flatten()\n",
    "\n",
    "# Define the threshold values\n",
    "click_threshold = 0.5  # Set your click threshold here\n",
    "like_threshold = 0.5  # Set your like threshold here\n",
    "\n",
    "# Convert predictions to zeros and ones\n",
    "click_predictions_binary = (click_predictions >= click_threshold).astype(int)\n",
    "like_predictions_binary = (like_predictions >= like_threshold).astype(int)\n",
    "\n",
    "print(\"Click Predictions (Binary):\\n\", click_predictions_binary)\n",
    "print(\"Like Predictions (Binary):\\n\", like_predictions_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "96a7cffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Click Accuracy: 0.604858\n",
      "Like Accuracy: 0.718606\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming 'click_labels' and 'like_labels' are the actual labels\n",
    "click_labels = data['click'].values\n",
    "like_labels = data['like'].values\n",
    "\n",
    "# Calculate accuracy for click task\n",
    "click_accuracy = accuracy_score(click_labels, click_predictions_binary)\n",
    "\n",
    "# Calculate accuracy for like task\n",
    "like_accuracy = accuracy_score(like_labels, like_predictions_binary)\n",
    "\n",
    "print(\"Click Accuracy:\", click_accuracy)\n",
    "print(\"Like Accuracy:\", like_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e1cf86",
   "metadata": {},
   "source": [
    "The accuracy achieved for the click and like tasks, which are approximately 0.6049 and 0.7186, respectively. These values represent the proportion of correct predictions for each task, with a value of 1.0 indicating perfect accuracy and a value of 0.0 indicating no accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "193f7062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Click Precision: 0.24998343207814758\n",
      "Click Recall: 0.3088872329449144\n",
      "Click F1-score: 0.2763311637174787\n",
      "Click ROC-AUC: 0.5046967384870596\n",
      "Click PR-AUC: 0.24601269061669195\n",
      "Like Precision: 0.02054385752939152\n",
      "Like Recall: 0.2878469194069666\n",
      "Like F1-score: 0.03835060283784892\n",
      "Like ROC-AUC: 0.5075083193730217\n",
      "Like PR-AUC: 0.019795486102570967\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, average_precision_score\n",
    "\n",
    "# Calculate other evaluation metrics for click task\n",
    "click_precision = precision_score(click_labels, click_predictions_binary)\n",
    "click_recall = recall_score(click_labels, click_predictions_binary)\n",
    "click_f1_score = f1_score(click_labels, click_predictions_binary)\n",
    "click_roc_auc = roc_auc_score(click_labels, click_predictions_binary)\n",
    "click_pr_auc = average_precision_score(click_labels, click_predictions_binary)\n",
    "\n",
    "# Calculate other evaluation metrics for like task\n",
    "like_precision = precision_score(like_labels, like_predictions_binary)\n",
    "like_recall = recall_score(like_labels, like_predictions_binary)\n",
    "like_f1_score = f1_score(like_labels, like_predictions_binary)\n",
    "like_roc_auc = roc_auc_score(like_labels, like_predictions_binary)\n",
    "like_pr_auc = average_precision_score(like_labels, like_predictions_binary)\n",
    "\n",
    "print(\"Click Precision:\", click_precision)\n",
    "print(\"Click Recall:\", click_recall)\n",
    "print(\"Click F1-score:\", click_f1_score)\n",
    "print(\"Click ROC-AUC:\", click_roc_auc)\n",
    "print(\"Click PR-AUC:\", click_pr_auc)\n",
    "\n",
    "print(\"Like Precision:\", like_precision)\n",
    "print(\"Like Recall:\", like_recall)\n",
    "print(\"Like F1-score:\", like_f1_score)\n",
    "print(\"Like ROC-AUC:\", like_roc_auc)\n",
    "print(\"Like PR-AUC:\", like_pr_auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd2359e",
   "metadata": {},
   "source": [
    "Based on the evaluation metrics, the model's performance for both the click and like tasks:\n",
    "\n",
    "Click Task:\n",
    "Precision: 0.250\n",
    "Recall: 0.309\n",
    "F1-score: 0.276\n",
    "ROC-AUC: 0.505\n",
    "PR-AUC: 0.246\n",
    "The click task shows modest performance with relatively low precision, recall, and F1-score. The ROC-AUC value being close to 0.5 suggests that the model's ability to distinguish between positive and negative samples for the click task is not significantly better than random chance. The PR-AUC score, which takes into account the imbalanced nature of the dataset, also indicates a limited ability to identify positive samples.\n",
    "\n",
    "Like Task:\n",
    "Precision: 0.021\n",
    "Recall: 0.288\n",
    "F1-score: 0.038\n",
    "ROC-AUC: 0.508\n",
    "PR-AUC: 0.020\n",
    "The like task also demonstrates poor performance with low precision, recall, and F1-score. The ROC-AUC value close to 0.5 indicates that the model's ability to discriminate between positive and negative samples for the like task is not much better than random guessing. The PR-AUC score, accounting for class imbalance, shows limited success in identifying positive samples for the like task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce44230",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbff4bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
